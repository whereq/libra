# Spark Configuration Template for AWS S3 Integration
#
# Environment-specific values should be provided via K8s ConfigMaps.

# ============================================================================
# S3 Hadoop Configuration (Static)
# ============================================================================
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled=true
spark.hadoop.fs.s3a.path.style.access=false

# Performance Tuning
spark.hadoop.fs.s3a.block.size=134217728
spark.hadoop.fs.s3a.connection.maximum=100
spark.hadoop.fs.s3a.threads.max=20
spark.hadoop.fs.s3a.connection.timeout=200000
spark.hadoop.fs.s3a.attempts.maximum=20

# Multipart Upload
spark.hadoop.fs.s3a.multipart.size=104857600
spark.hadoop.fs.s3a.multipart.threshold=209715200
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.fast.upload.buffer=disk

# ============================================================================
# Event Logging & History Server
# ============================================================================
spark.eventLog.enabled=true
# spark.eventLog.dir=s3a://${S3_BUCKET}/spark_events
# spark.history.fs.logDirectory=s3a://${S3_BUCKET}/spark_events

# ============================================================================
# SQL & Metastore
# ============================================================================
# spark.sql.warehouse.dir=s3a://${S3_BUCKET}/spark_warehouse
spark.hadoop.datanucleus.schema.autoCreateAll=true

# ============================================================================
# UI & Monitoring
# ============================================================================
spark.ui.showConsoleProgress=true
spark.redaction.regex=(?i)secret|password|key

# ============================================================================
# Serialization
# ============================================================================
com.fasterxml.jackson.core.StreamReadConstraints.maxStringLength=25000000

# ============================================================================
# Dynamic Configuration (Set at runtime)
# ============================================================================
# spark.master=spark://spark-master-svc:7077
# spark.submit.deployMode=client
# spark.scheduler.mode=FAIR
# spark.hadoop.fs.default.name=s3a://${S3_BUCKET}/
