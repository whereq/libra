# Spark Configuration Template for GCS Integration
#
# This template contains BASE configurations for GCS-enabled Spark.
# Environment-specific values (master URL, buckets, etc.) should be
# provided via Kubernetes ConfigMaps or environment variables.
#
# DO NOT hardcode environment-specific values in this template.

# ============================================================================
# GCS Hadoop Configuration (Static - baked into image)
# ============================================================================
spark.hadoop.fs.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem
spark.hadoop.fs.AbstractFileSystem.gs.impl=com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS

# GCS Authentication (Service Account JSON - default method)
spark.hadoop.google.cloud.auth.service.account.enable=true
spark.hadoop.fs.gs.auth.type=SERVICE_ACCOUNT_JSON_KEYFILE
spark.hadoop.fs.gs.auth.service.account.json.keyfile=/opt/spark/conf/gcs-json-key/gcs-key.json
spark.hadoop.google.cloud.auth.type=SERVICE_ACCOUNT_JSON_KEYFILE
spark.hadoop.google.cloud.auth.service.account.json.keyfile=/opt/spark/conf/gcs-json-key/gcs-key.json

# GCS Performance Tuning
spark.hadoop.fs.gs.block.size=134217728
spark.hadoop.fs.gs.http.max.retry=10
spark.hadoop.fs.gs.http.connect-timeout=60000
spark.hadoop.fs.gs.http.read-timeout=60000

# ============================================================================
# Event Logging & History Server (Configure via environment variables)
# ============================================================================
spark.eventLog.enabled=true
# spark.eventLog.dir=gs://${GCS_BUCKET}/spark_events
# spark.history.fs.logDirectory=gs://${GCS_BUCKET}/spark_events

# ============================================================================
# SQL & Metastore Configuration
# ============================================================================
# spark.sql.warehouse.dir=gs://${GCS_BUCKET}/spark_warehouse
spark.hadoop.datanucleus.schema.autoCreateAll=true

# ============================================================================
# UI & Monitoring
# ============================================================================
spark.ui.showConsoleProgress=true
spark.redaction.regex=(?i)secret|password|key

# ============================================================================
# Serialization & Jackson
# ============================================================================
com.fasterxml.jackson.core.StreamReadConstraints.maxStringLength=25000000

# ============================================================================
# Dynamic Configuration (Set at runtime via K8s ConfigMap or environment)
# ============================================================================
# spark.master=spark://spark-master-svc:7077
# spark.submit.deployMode=client
# spark.scheduler.mode=FAIR
# spark.hadoop.fs.default.name=gs://${GCS_BUCKET}/
# spark.hadoop.fs.gs.project.id=${GCS_PROJECT_ID}

# ============================================================================
# Example K8s ConfigMap Usage:
# ============================================================================
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: spark-config-dev
# data:
#   spark-env-overrides.conf: |
#     spark.master=spark://spark-master-svc:7077
#     spark.submit.deployMode=client
#     spark.scheduler.mode=FAIR
#     spark.hadoop.fs.default.name=gs://dev-bucket/
#     spark.eventLog.dir=gs://dev-bucket/spark_events
#     spark.history.fs.logDirectory=gs://dev-bucket/spark_events
#     spark.sql.warehouse.dir=gs://dev-bucket/spark_warehouse/
