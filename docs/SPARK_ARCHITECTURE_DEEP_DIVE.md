# Spark Architecture Deep Dive

**Understanding Driver, Master, Workers, and Executors**

---

## Table of Contents

1. [Overview](#overview)
2. [Core Components](#core-components)
3. [Deployment Modes](#deployment-modes)
4. [Component Interactions](#component-interactions)
5. [WhereQ Libra's Role](#whereq-libras-role)
6. [Real-World Examples](#real-world-examples)
7. [Common Misconceptions](#common-misconceptions)

---

## Overview

Apache Spark has a **master-worker architecture** with distinct roles for different components. Understanding these components is crucial for deploying and optimizing Spark applications.

### The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Spark Application Lifecycle                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  User Code (SparkSession)                                       â”‚
â”‚         â†“                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚    DRIVER    â”‚  â† The brain (your application JVM)           â”‚
â”‚  â”‚   Process    â”‚    - Analyzes code                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    - Creates execution plan                   â”‚
â”‚         â”‚            - Schedules tasks                          â”‚
â”‚         â”‚            - Coordinates executors                    â”‚
â”‚         â†“                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚ CLUSTER      â”‚  â† Resource manager (Spark Standalone,        â”‚
â”‚  â”‚ MANAGER      â”‚    YARN, Kubernetes, Mesos)                   â”‚
â”‚  â”‚ (Master)     â”‚    - Allocates resources                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    - Monitors cluster health                  â”‚
â”‚         â”‚                                                       â”‚
â”‚         â†“                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚         WORKER NODES                â”‚                        â”‚
â”‚  â”‚  (Physical/Virtual Machines)        â”‚                        â”‚
â”‚  â”‚                                     â”‚                        â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                         â”‚
â”‚  â”‚  â”‚  EXECUTOR 1 â”‚  â”‚  EXECUTOR 2 â”‚  â”‚  â† JVM processes        â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚  â”‚    - Run tasks          â”‚
â”‚  â”‚  â”‚  Task Task  â”‚  â”‚  Task Task  â”‚  â”‚    - Store data         â”‚
â”‚  â”‚  â”‚  Task Task  â”‚  â”‚  Task Task  â”‚  â”‚    - Return results     â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Core Components

### 1. Driver (The Brain) ğŸ§ 

**What is it?**
- The **JVM process** that runs your `main()` method
- Contains the **SparkContext** (or **SparkSession** in Spark 2.0+)
- The **application coordinator** and **task scheduler**

**Key Responsibilities:**
1. **Analyzes your code** and creates a Directed Acyclic Graph (DAG) of stages
2. **Converts transformations** into physical execution plans
3. **Schedules tasks** and sends them to executors
4. **Monitors task execution** and handles failures
5. **Aggregates results** from executors
6. **Manages metadata** (RDD lineage, DataFrame schemas)

**Important Characteristics:**
- **Single Point of Failure**: If driver crashes, the entire application fails
- **Memory-intensive**: Holds execution plan, metadata, and collects results
- **CPU-intensive**: Creates execution plans, schedules tasks
- **Network-intensive**: Communicates with all executors

**Example Code:**
```java
// When you create a SparkSession, you're creating the Driver
SparkSession spark = SparkSession.builder()
    .appName("MyApp")
    .master("spark://master-node:7077")
    .getOrCreate();

// The Driver analyzes this code
Dataset<Row> df = spark.read().parquet("/data/large.parquet");
df.filter(col("age").gt(30))
  .groupBy("city")
  .count()
  .show();  // Driver collects results here

// Driver runs in THIS JVM process
```

**Driver Location Examples:**

| Deployment Mode | Driver Location | Example |
|-----------------|-----------------|---------|
| **client mode** | Your laptop/submit machine | `spark-submit --deploy-mode client` |
| **cluster mode** | Inside the cluster | `spark-submit --deploy-mode cluster` |
| **Libra (embedded)** | Inside Libra's JVM | WhereQ Libra IS the driver |

---

### 2. Master (Cluster Manager) ğŸ›ï¸

**What is it?**
- The **resource manager** for the cluster
- Responsible for **allocating resources** to applications
- **NOT the same as the Driver** (common misconception!)

**Types of Cluster Managers:**

#### A. Spark Standalone Master
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Spark Standalone Master        â”‚
â”‚  (spark://master:7077)          â”‚
â”‚                                 â”‚
â”‚  Responsibilities:              â”‚
â”‚  âœ“ Register Worker nodes        â”‚
â”‚  âœ“ Track available resources    â”‚
â”‚  âœ“ Allocate cores/memory        â”‚
â”‚  âœ“ Monitor Worker health        â”‚
â”‚  âœ“ Reschedule on failures       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Configuration:**
```bash
# Start Master
./sbin/start-master.sh

# Master UI: http://master-node:8080
# Master URL: spark://master-node:7077
```

#### B. YARN ResourceManager
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YARN ResourceManager           â”‚
â”‚                                 â”‚
â”‚  Components:                    â”‚
â”‚  â”œâ”€ ResourceManager (RM)        â”‚
â”‚  â”œâ”€ NodeManagers (NM)           â”‚
â”‚  â””â”€ ApplicationMaster (AM)      â”‚
â”‚                                 â”‚
â”‚  Spark Integration:             â”‚
â”‚  â”œâ”€ AM manages Spark executors  â”‚
â”‚  â””â”€ NM runs executor containers â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### C. Kubernetes Master
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Kubernetes API Server          â”‚
â”‚                                 â”‚
â”‚  Spark on K8s:                  â”‚
â”‚  â”œâ”€ Driver Pod                  â”‚
â”‚  â””â”€ Executor Pods (dynamic)     â”‚
â”‚                                 â”‚
â”‚  Resource Management:           â”‚
â”‚  â”œâ”€ CPU requests/limits         â”‚
â”‚  â”œâ”€ Memory requests/limits      â”‚
â”‚  â””â”€ Pod scheduling              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### D. Apache Mesos
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mesos Master                   â”‚
â”‚                                 â”‚
â”‚  Two-level scheduling:          â”‚
â”‚  â”œâ”€ Mesos offers resources      â”‚
â”‚  â””â”€ Spark accepts/rejects       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Point:** The Master **allocates resources** but does **NOT execute your code**. The Driver executes code logic.

---

### 3. Worker Nodes (Physical Resources) ğŸ–¥ï¸

**What is it?**
- **Physical or virtual machines** in the cluster
- Provide **CPU cores and memory** for executors
- Managed by the **cluster manager**

**Worker Responsibilities:**
1. **Register with Master** on startup
2. **Report available resources** (cores, memory)
3. **Launch executor JVMs** when requested
4. **Monitor executor health** and report to Master
5. **Clean up resources** when executors terminate

**Example Worker Node:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker Node (Physical Machine)                 â”‚
â”‚  IP: 192.168.1.101                              â”‚
â”‚  Total Resources: 32 cores, 128GB RAM           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Executor 1 (App-1)              â”‚           â”‚
â”‚  â”‚  Allocated: 8 cores, 32GB        â”‚           â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚           â”‚
â”‚  â”‚  â”‚ Task 1 â”‚ â”‚ Task 2 â”‚           â”‚           â”‚
â”‚  â”‚  â”‚ Task 3 â”‚ â”‚ Task 4 â”‚           â”‚           â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Executor 2 (App-2)              â”‚           â”‚
â”‚  â”‚  Allocated: 4 cores, 16GB        â”‚           â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚           â”‚
â”‚  â”‚  â”‚ Task 1 â”‚ â”‚ Task 2 â”‚           â”‚           â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                 â”‚
â”‚  Available: 20 cores, 80GB                      â”‚
â”‚  (Can launch more executors)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Worker Configuration:**
```bash
# Start Worker (Spark Standalone)
./sbin/start-worker.sh spark://master:7077

# Worker UI: http://worker-node:8081
# Registers with Master at spark://master:7077
```

**Key Point:** Workers are **containers for executors**. They don't execute tasks directly.

---

### 4. Executors (The Workers) âš™ï¸

**What is it?**
- **JVM processes** running on worker nodes
- **Execute tasks** sent by the Driver
- **Store data** for the application (RDD partitions, cached DataFrames)

**Executor Lifecycle:**
```
1. Driver requests executors from Master
2. Master allocates resources on Workers
3. Workers launch executor JVMs
4. Executors register with Driver
5. Driver sends tasks to executors
6. Executors run tasks and return results
7. Executors cache data if requested
8. When app finishes, executors terminate
```

**Executor Anatomy:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Executor JVM Process                           â”‚
â”‚  (e.g., executor-1 on Worker Node 1)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Thread Pool                     â”‚           â”‚
â”‚  â”‚  (executor.cores threads)        â”‚           â”‚
â”‚  â”‚                                  â”‚           â”‚
â”‚  â”‚  Thread 1: Running Task 1        â”‚           â”‚
â”‚  â”‚  Thread 2: Running Task 2        â”‚           â”‚
â”‚  â”‚  Thread 3: Running Task 3        â”‚           â”‚
â”‚  â”‚  Thread 4: Running Task 4        â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Block Manager                   â”‚           â”‚
â”‚  â”‚  (Storage for cached data)       â”‚           â”‚
â”‚  â”‚                                  â”‚           â”‚
â”‚  â”‚  RDD Partition 1: 500MB          â”‚           â”‚
â”‚  â”‚  RDD Partition 5: 300MB          â”‚           â”‚
â”‚  â”‚  Broadcast Var: 100MB            â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚  Shuffle Service                 â”‚           â”‚
â”‚  â”‚  (Write/Read shuffle data)       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                 â”‚
â”‚  Memory: executor.memory (e.g., 8GB)            â”‚
â”‚  Cores: executor.cores (e.g., 4)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Executor Configuration:**
```bash
# When submitting an application
spark-submit \
  --executor-memory 8g \        # Memory per executor
  --executor-cores 4 \           # CPU cores per executor
  --num-executors 10 \           # Total number of executors
  --driver-memory 4g \           # Driver memory
  myapp.jar
```

**Key Point:** Executors are **long-lived** (run for entire application) and **multi-threaded** (run multiple tasks concurrently).

---

## Deployment Modes

### 1. Standalone Cluster Mode

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Standalone Cluster                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚  Spark Master    â”‚  spark://master:7077                      â”‚
â”‚  â”‚  (Resource Mgr)  â”‚  UI: http://master:8080                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚           â”‚                                                     â”‚
â”‚           â”‚ (Manages Workers)                                   â”‚
â”‚           â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚                                              â”‚               â”‚
â”‚  â†“                        â†“                     â†“               â”‚
â”‚  Worker 1                 Worker 2              Worker 3        â”‚
â”‚  192.168.1.101           192.168.1.102          192.168.1.103   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Executor 1   â”‚        â”‚ Executor 2   â”‚      â”‚ Executor 3   â”‚ â”‚
â”‚  â”‚ 8GB, 4 cores â”‚        â”‚ 8GB, 4 cores â”‚      â”‚ 8GB, 4 cores â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  Total Capacity: 24GB, 12 cores                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Driver          â”‚  (Runs on client machine OR in cluster)
â”‚  (Your App)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ (Communicates with executors)
         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ All Executors
```

**Client Mode:**
```bash
spark-submit \
  --master spark://master:7077 \
  --deploy-mode client \          # Driver runs on submit machine
  --executor-memory 8g \
  --num-executors 3 \
  myapp.jar

# Driver runs on YOUR laptop
# Executors run in the cluster
# If your laptop disconnects, app fails
```

**Cluster Mode:**
```bash
spark-submit \
  --master spark://master:7077 \
  --deploy-mode cluster \         # Driver runs in cluster
  --executor-memory 8g \
  --num-executors 3 \
  myapp.jar

# Driver runs on one of the Worker nodes
# Executors run on Worker nodes
# Submit machine can disconnect
```

---

### 2. YARN Cluster Mode

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        YARN Cluster                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚ ResourceManager  â”‚  (YARN Master)                            â”‚
â”‚  â”‚    (RM)          â”‚  - Allocates containers                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Schedules applications                 â”‚
â”‚           â”‚                                                     â”‚
â”‚           â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  NodeManager 1    NodeManager 2    NodeManager 3â”‚            â”‚
â”‚  â”‚  (Worker Nodes)                                 â”‚            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  â”‚                                                 â”‚            â”‚
â”‚  â”‚  Container 1           Container 2              â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚            â”‚
â”‚  â”‚  â”‚ Application  â”‚     â”‚ Spark        â”‚          â”‚            â”‚
â”‚  â”‚  â”‚ Master (AM)  â”‚     â”‚ Executor 1   â”‚          â”‚            â”‚
â”‚  â”‚  â”‚ + Driver     â”‚     â”‚              â”‚          â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚            â”‚
â”‚  â”‚                                                 â”‚            â”‚
â”‚  â”‚  Container 3           Container 4              â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚            â”‚
â”‚  â”‚  â”‚ Spark        â”‚     â”‚ Spark        â”‚          â”‚            â”‚
â”‚  â”‚  â”‚ Executor 2   â”‚     â”‚ Executor 3   â”‚          â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Differences:**
- **ApplicationMaster (AM)** manages Spark executors
- In **cluster mode**, Driver runs inside AM container
- In **client mode**, Driver runs on submit machine, AM just manages executors

---

### 3. Kubernetes Native Mode

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes Cluster                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚  K8s API Server  â”‚  (Master)                                 â”‚
â”‚  â”‚  (Scheduler)     â”‚  - Schedules pods                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Manages resources                      â”‚
â”‚           â”‚                                                     â”‚
â”‚           â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚            Kubernetes Nodes (Workers)           â”‚            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  â”‚                                                 â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚            â”‚
â”‚  â”‚  â”‚  Driver Pod                       â”‚          â”‚            â”‚
â”‚  â”‚  â”‚  spark-driver-xyz                 â”‚          â”‚            â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚          â”‚            â”‚
â”‚  â”‚  â”‚  â”‚  Spark Driver Container     â”‚  â”‚          â”‚            â”‚
â”‚  â”‚  â”‚  â”‚  (SparkContext)             â”‚  â”‚          â”‚            â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚          â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚            â”‚
â”‚  â”‚                                                 â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚            â”‚
â”‚  â”‚  â”‚ Executor Pod 1  â”‚  â”‚ Executor Pod 2  â”‚       â”‚            â”‚
â”‚  â”‚  â”‚ spark-exec-1    â”‚  â”‚ spark-exec-2    â”‚       â”‚            â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚            â”‚
â”‚  â”‚  â”‚ â”‚ Executor    â”‚ â”‚  â”‚ â”‚ Executor    â”‚ â”‚       â”‚            â”‚
â”‚  â”‚  â”‚ â”‚ Container   â”‚ â”‚  â”‚ â”‚ Container   â”‚ â”‚       â”‚            â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚            â”‚
â”‚  â”‚                                                 â”‚            â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚            â”‚
â”‚  â”‚  â”‚ Executor Pod 3  â”‚  (Dynamic scaling)         â”‚            â”‚
â”‚  â”‚  â”‚ spark-exec-3    â”‚                            â”‚            â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Configuration:**
```bash
spark-submit \
  --master k8s://https://k8s-api-server:6443 \
  --deploy-mode cluster \
  --name spark-pi \
  --conf spark.kubernetes.container.image=my-spark:4.0.1 \
  --conf spark.kubernetes.namespace=spark-apps \
  --conf spark.executor.instances=3 \
  --conf spark.executor.memory=8g \
  --conf spark.executor.cores=4 \
  local:///opt/spark/examples/jars/spark-examples.jar
```

---

## Component Interactions

### Example: Word Count Application

Let's trace a simple word count application through all components:

```java
// User submits this code
SparkSession spark = SparkSession.builder().appName("WordCount").getOrCreate();
Dataset<String> lines = spark.read().textFile("/data/large.txt");
Dataset<Row> words = lines.flatMap(line -> Arrays.asList(line.split(" ")).iterator(), Encoders.STRING());
Dataset<Row> counts = words.groupBy("value").count();
counts.show();
```

#### Step-by-Step Execution:

```
Step 1: Application Submission
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User submits â”‚  spark-submit --master spark://master:7077 wordcount.jar
â”‚ application  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 2: Driver Starts
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Driver Process (JVM)                             â”‚
â”‚ - Creates SparkContext                           â”‚
â”‚ - Contacts Master to request resources           â”‚
â”‚ - Requests: 3 executors, 8GB each, 4 cores each  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 3: Master Allocates Resources
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Spark Master                                     â”‚
â”‚ - Finds available Workers                        â”‚
â”‚ - Allocates: Worker1(1 exec), Worker2(1 exec),   â”‚
â”‚              Worker3(1 exec)                     â”‚
â”‚ - Tells Workers to launch executors              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 4: Workers Launch Executors
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Worker 1          Worker 2          Worker 3                â”‚
â”‚ â””â”€ Executor 1     â””â”€ Executor 2     â””â”€ Executor 3           â”‚
â”‚    (8GB, 4 cores)    (8GB, 4 cores)    (8GB, 4 cores)       â”‚
â”‚                                                             â”‚
â”‚ Each executor registers with Driver                         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 5: Driver Creates Execution Plan
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Driver analyzes code and creates DAG:            â”‚
â”‚                                                  â”‚
â”‚ Stage 1: Read file (textFile)                    â”‚
â”‚   â””â”€ Task 1: Read partition 1 â†’ Executor 1       â”‚
â”‚   â””â”€ Task 2: Read partition 2 â†’ Executor 2       â”‚
â”‚   â””â”€ Task 3: Read partition 3 â†’ Executor 3       â”‚
â”‚                                                  â”‚
â”‚ Stage 2: FlatMap + GroupBy (shuffle)             â”‚
â”‚   â””â”€ Task 4: Map partition 1 â†’ Executor 1        â”‚
â”‚   â””â”€ Task 5: Map partition 2 â†’ Executor 2        â”‚
â”‚   â””â”€ Task 6: Map partition 3 â†’ Executor 3        â”‚
â”‚                                                  â”‚
â”‚ Stage 3: Count and collect                       â”‚
â”‚   â””â”€ Task 7: Reduce â†’ Executor 1                 â”‚
â”‚   â””â”€ Task 8: Reduce â†’ Executor 2                 â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 6: Driver Sends Tasks to Executors
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Driver â†’ Executor 1: Run Task 1 (read partition 1)          â”‚
â”‚ Driver â†’ Executor 2: Run Task 2 (read partition 2)          â”‚
â”‚ Driver â†’ Executor 3: Run Task 3 (read partition 3)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 7: Executors Execute Tasks
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Executor 1:                                                 â”‚
â”‚   - Reads /data/large.txt partition 1 from HDFS             â”‚
â”‚   - Splits into words                                       â”‚
â”‚   - Stores intermediate results in memory                   â”‚
â”‚                                                             â”‚
â”‚ Executor 2:                                                 â”‚
â”‚   - Reads /data/large.txt partition 2 from HDFS             â”‚
â”‚   - Splits into words                                       â”‚
â”‚   - Stores intermediate results in memory                   â”‚
â”‚                                                             â”‚
â”‚ Executor 3:                                                 â”‚
â”‚   - Reads /data/large.txt partition 3 from HDFS             â”‚
â”‚   - Splits into words                                       â”‚
â”‚   - Stores intermediate results in memory                   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 8: Shuffle Phase
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Executors write shuffle data to disk:                       â”‚
â”‚                                                             â”‚
â”‚ Executor 1 writes:                                          â”‚
â”‚   - Words starting with A-J â†’ /tmp/shuffle/partition-0      â”‚
â”‚   - Words starting with K-R â†’ /tmp/shuffle/partition-1      â”‚
â”‚   - Words starting with S-Z â†’ /tmp/shuffle/partition-2      â”‚
â”‚                                                             â”‚
â”‚ Executors read shuffle data:                                â”‚
â”‚   - Executor 1 reads all partition-0 files                  â”‚
â”‚   - Executor 2 reads all partition-1 files                  â”‚
â”‚   - Executor 3 reads all partition-2 files                  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 9: Aggregation
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Executor 1: Counts words A-J                                â”‚
â”‚   - apple: 150                                              â”‚
â”‚   - banana: 75                                              â”‚
â”‚   - ...                                                     â”‚
â”‚                                                             â”‚
â”‚ Executor 2: Counts words K-R                                â”‚
â”‚   - kiwi: 30                                                â”‚
â”‚   - mango: 90                                               â”‚
â”‚   - ...                                                     â”‚
â”‚                                                             â”‚
â”‚ Executor 3: Counts words S-Z                                â”‚
â”‚   - strawberry: 120                                         â”‚
â”‚   - watermelon: 60                                          â”‚
â”‚   - ...                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
Step 10: Collect Results
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Driver calls counts.show():                                 â”‚
â”‚ - Requests results from all executors                       â”‚
â”‚ - Executor 1 sends results to Driver                        â”‚
â”‚ - Executor 2 sends results to Driver                        â”‚
â”‚ - Executor 3 sends results to Driver                        â”‚
â”‚                                                             â”‚
â”‚ Driver combines and displays:                               â”‚
â”‚ +------------+-----+                                        â”‚
â”‚ |       value|count|                                        â”‚
â”‚ +------------+-----+                                        â”‚
â”‚ |       apple|  150|                                        â”‚
â”‚ |      banana|   75|                                        â”‚
â”‚ |        kiwi|   30|                                        â”‚
â”‚ |       mango|   90|                                        â”‚
â”‚ |  strawberry|  120|                                        â”‚
â”‚ |  watermelon|   60|                                        â”‚
â”‚ +------------+-----+                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## WhereQ Libra's Role

### Libra as the Spark Driver

**Key Understanding:** WhereQ Libra **IS** the Spark Driver, not a proxy or middleware.

```
Traditional Spark Application:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your Application JAR                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  main() {                                  â”‚          â”‚
â”‚  â”‚    SparkSession spark = ...                â”‚          â”‚
â”‚  â”‚    Dataset<Row> df = spark.read()...       â”‚  â† Driverâ”‚
â”‚  â”‚    df.show()                               â”‚          â”‚
â”‚  â”‚  }                                         â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“ communicates with
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Executors   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


WhereQ Libra Application:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Libra Spring Boot Application                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  SparkSessionService {                     â”‚          â”‚
â”‚  â”‚    SparkSession spark = ...  â† Embedded!   â”‚  â† Driverâ”‚
â”‚  â”‚                                            â”‚          â”‚
â”‚  â”‚    executeJob(request) {                   â”‚          â”‚
â”‚  â”‚      spark.read()...                       â”‚          â”‚
â”‚  â”‚      df.show()                             â”‚          â”‚
â”‚  â”‚    }                                       â”‚          â”‚
â”‚  â”‚  }                                         â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  REST API (Port 8080)                      â”‚          â”‚
â”‚  â”‚  POST /api/v1/sessions/default/statements  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“ communicates with
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Executors   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Libra's Architecture with Spark Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Full Picture                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  WhereQ Libra Container (Driver Process)             â”‚       â”‚
â”‚  â”‚  IP: 192.168.1.100                                   â”‚       â”‚
â”‚  â”‚                                                      â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚       â”‚
â”‚  â”‚  â”‚  Spring Boot Application                    â”‚     â”‚       â”‚
â”‚  â”‚  â”‚                                             â”‚     â”‚       â”‚
â”‚  â”‚  â”‚  REST API (:8080)                           â”‚     â”‚       â”‚
â”‚  â”‚  â”‚    â†“                                        â”‚     â”‚       â”‚
â”‚  â”‚  â”‚  SparkSessionService                        â”‚     â”‚       â”‚
â”‚  â”‚  â”‚    â†“                                        â”‚     â”‚       â”‚
â”‚  â”‚  â”‚  SparkSession (Driver)                      â”‚     â”‚       â”‚
â”‚  â”‚  â”‚    - Task Scheduler                         â”‚     â”‚       â”‚
â”‚  â”‚  â”‚    - DAG Scheduler                          â”‚     â”‚       â”‚
â”‚  â”‚  â”‚    - BlockManager                           â”‚     â”‚       â”‚
â”‚  â”‚  â”‚    - Executor Coordinator                   â”‚     â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚       â”‚
â”‚  â”‚                                                      â”‚       â”‚
â”‚  â”‚  Memory: 4GB (driver.memory)                         â”‚       â”‚
â”‚  â”‚  Port: 8080 (REST), 4040 (Spark UI)                  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                     â”‚                                           â”‚
â”‚                     â”‚ (Connects to Spark Cluster)               â”‚
â”‚                     â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚  Spark Standalone Master                             â”‚       â”‚
â”‚  â”‚  spark://spark-master:7077                           â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                     â”‚                                           â”‚
â”‚                     â”‚ (Manages Workers)                         â”‚
â”‚                     â†“                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    Worker Nodes                         â”‚    â”‚
â”‚  â”‚                                                         â”‚    â”‚
â”‚  â”‚  Worker 1          Worker 2          Worker 3           â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚    â”‚
â”‚  â”‚  â”‚Executor 1â”‚      â”‚Executor 2â”‚      â”‚Executor 3â”‚       â”‚    â”‚
â”‚  â”‚  â”‚8GB,4coresâ”‚      â”‚8GB,4coresâ”‚      â”‚8GB,4coresâ”‚       â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Libra's Two Execution Modes

#### Mode 1: SHARED (Single Driver, Multiple Jobs)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Libra Process (Single Driver)                                  â”‚
â”‚                                                                 â”‚
â”‚  SparkSession (shared)                                          â”‚
â”‚    â””â”€ FAIR Scheduler                                            â”‚
â”‚       â”œâ”€ Pool: default                                          â”‚
â”‚       â”‚  â””â”€ Job 1 (SQL query) â†’ Tasks 1-10                      â”‚
â”‚       â”‚                                                         â”‚
â”‚       â”œâ”€ Pool: high-priority                                    â”‚
â”‚       â”‚  â””â”€ Job 2 (ETL) â†’ Tasks 11-20                           â”‚
â”‚       â”‚                                                         â”‚
â”‚       â””â”€ Pool: low-priority                                     â”‚
â”‚          â””â”€ Job 3 (ML training) â†’ Tasks 21-50                   â”‚
â”‚                                                                 â”‚
â”‚  All jobs share same SparkSession and executors                 â”‚
â”‚  Resources: 2GB driver, 2GB Ã— 3 executors (global config)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“ All jobs share these executors
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Executor 1       Executor 2       Executor 3                   â”‚
â”‚  Task 1,11,21    Task 2,12,22     Task 3,13,23                  â”‚
â”‚  (interleaved)   (interleaved)    (interleaved)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Mode 2: ISOLATED (Multiple Drivers via spark-submit)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Libra Process (REST API)                                       â”‚
â”‚                                                                 â”‚
â”‚  Request 1: jar-class with sparkConfig                          â”‚
â”‚    â””â”€ Launches: spark-submit (separate JVM)                     â”‚
â”‚       â””â”€ Driver 1 (dedicated 8GB)                               â”‚
â”‚          â””â”€ Executors: 16GB Ã— 10                                â”‚
â”‚             â””â”€ Job 1 tasks                                      â”‚
â”‚                                                                 â”‚
â”‚  Request 2: python-file with sparkConfig                        â”‚
â”‚    â””â”€ Launches: spark-submit (separate JVM)                     â”‚
â”‚       â””â”€ Driver 2 (dedicated 4GB)                               â”‚
â”‚          â””â”€ Executors: 8GB Ã— 5                                  â”‚
â”‚             â””â”€ Job 2 tasks                                      â”‚
â”‚                                                                 â”‚
â”‚  Each job has isolated resources                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Libra Differs from Apache Livy

```
Apache Livy (Proxy Model):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client      â”‚  HTTP â”‚  Livy Server â”‚       â”‚  Spark       â”‚
â”‚  (curl/SDK)  â”‚â”€â”€â”€â”€â”€â”€â†’â”‚  (Proxy)     â”‚â”€â”€â”€â”€â”€â”€â†’â”‚  Driver      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                     â†“
                                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                               â”‚  Executors   â”‚
                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

WhereQ Libra (Embedded Driver Model):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client      â”‚  HTTP â”‚  Libra (Driver Embedded)   â”‚
â”‚  (curl/SDK)  â”‚â”€â”€â”€â”€â”€â”€â†’â”‚  Spring Boot + SparkSessionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â†“
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚  Executors   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Key Difference: Libra eliminates the proxy layer - it IS the driver!
```

---

## Real-World Examples

### Example 1: E-Commerce Analytics Platform

**Scenario:** Real-time product analytics with 1000 concurrent users

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Infrastructure Setup                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Master Node (Spark Master):                                    â”‚
â”‚  - EC2 m5.xlarge (4 vCPU, 16GB RAM)                             â”‚
â”‚  - Coordinates cluster resources                                â”‚
â”‚                                                                 â”‚
â”‚  Driver Node (WhereQ Libra):                                    â”‚
â”‚  - EC2 m5.2xlarge (8 vCPU, 32GB RAM)                            â”‚
â”‚  - Runs Libra Spring Boot app                                   â”‚
â”‚  - Driver memory: 16GB                                          â”‚
â”‚  - Handles 1000 concurrent REST API requests                    â”‚
â”‚                                                                 â”‚
â”‚  Worker Nodes (10 nodes):                                       â”‚
â”‚  - EC2 r5.4xlarge (16 vCPU, 128GB RAM) Ã— 10                     â”‚
â”‚  - Each runs 4 executors (4GB each)                             â”‚
â”‚  - Total: 40 executors, 160GB executor memory                   â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

API Request Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User submits â”‚ POST /api/v1/sessions/default/statements
â”‚ SQL query    â”‚ {
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   "kind": "sql",
       â”‚           "code": "SELECT product, SUM(sales) FROM orders
       â”‚                     WHERE date = '2025-11-03'
       â†“                     GROUP BY product",
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  "pool": "interactive"
â”‚ Libra REST Controller    â”‚}
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SparkSessionService (Driver)                               â”‚
â”‚                                                            â”‚
â”‚ 1. Receives SQL query                                      â”‚
â”‚ 2. Creates execution plan (DAG):                           â”‚
â”‚    - Stage 1: Scan Parquet files (200 partitions)          â”‚
â”‚    - Stage 2: Filter by date                               â”‚
â”‚    - Stage 3: Group by product (shuffle)                   â”‚
â”‚    - Stage 4: Aggregate sums                               â”‚
â”‚                                                            â”‚
â”‚ 3. Schedules 200 tasks across 40 executors                 â”‚
â”‚    - Each executor runs 5 tasks concurrently               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Executors (40 total across 10 workers)                      â”‚
â”‚                                                             â”‚
â”‚ Executor 1-4 (Worker 1):  Read partitions 1-20              â”‚
â”‚ Executor 5-8 (Worker 2):  Read partitions 21-40             â”‚
â”‚ Executor 9-12 (Worker 3): Read partitions 41-60             â”‚
â”‚ ...                                                         â”‚
â”‚ Executor 37-40 (Worker 10): Read partitions 181-200         â”‚
â”‚                                                             â”‚
â”‚ Shuffle: Re-partition by product                            â”‚
â”‚                                                             â”‚
â”‚ Final Aggregation:                                          â”‚
â”‚ Executor 1: Products A-D â†’ {iPhone: 1500, iPad: 800}        â”‚
â”‚ Executor 2: Products E-M â†’ {MacBook: 450, AirPods: 2000}    â”‚
â”‚ Executor 3: Products N-Z â†’ {Watch: 1200}                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Driver collects results                                    â”‚
â”‚ Returns to user via REST API:                              â”‚
â”‚ {                                                          â”‚
â”‚   "results": [                                             â”‚
â”‚     {"product": "iPhone", "total_sales": 1500},            â”‚
â”‚     {"product": "iPad", "total_sales": 800},               â”‚
â”‚     {"product": "MacBook", "total_sales": 450},            â”‚
â”‚     ...                                                    â”‚
â”‚   ]                                                        â”‚
â”‚ }                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Performance:
- Query execution: 8 seconds
- 200 partitions processed in parallel
- 40 executors Ã— 5 tasks = 200 concurrent tasks
- Total data scanned: 500GB
- Throughput: 62.5 GB/second
```

### Example 2: Machine Learning Pipeline

**Scenario:** Train recommendation model on 10TB dataset

```
API Request:
POST /api/v1/sessions/default/statements
{
  "kind": "python-file",
  "filePath": "/apps/ml/train_recommender.py",
  "args": ["/data/user_behavior_10tb.parquet", "/models/output"],
  "sparkConfig": {
    "spark.driver.memory": "32g",
    "spark.driver.cores": "16",
    "spark.executor.memory": "64g",
    "spark.executor.cores": "16",
    "spark.executor.instances": "100",
    "spark.dynamicAllocation.enabled": "false"
  }
}

Libra's Execution:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Libra detects sparkConfig and launches spark-submit            â”‚
â”‚                                                                â”‚
â”‚ spark-submit \                                                 â”‚
â”‚   --master spark://master:7077 \                               â”‚
â”‚   --deploy-mode cluster \                                      â”‚
â”‚   --driver-memory 32g \                                        â”‚
â”‚   --driver-cores 16 \                                          â”‚
â”‚   --executor-memory 64g \                                      â”‚
â”‚   --executor-cores 16 \                                        â”‚
â”‚   --num-executors 100 \                                        â”‚
â”‚   /apps/ml/train_recommender.py \                              â”‚
â”‚   /data/user_behavior_10tb.parquet /models/output              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cluster Allocation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Master receives request:                                       â”‚
â”‚ - Needs: 100 executors Ã— 64GB = 6.4TB executor memory          â”‚
â”‚ - Needs: 100 executors Ã— 16 cores = 1600 cores                 â”‚
â”‚                                                                â”‚
â”‚ Master allocates across 50 worker nodes:                       â”‚
â”‚ - Each worker: 2 executors (128GB, 32 cores per worker)        â”‚
â”‚                                                                â”‚
â”‚ Total Resources:                                               â”‚
â”‚ - Driver: 32GB, 16 cores                                       â”‚
â”‚ - Executors: 6.4TB, 1600 cores                                 â”‚
â”‚ - Total: 6.432TB, 1616 cores                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Execution Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Python Script: train_recommender.py                            â”‚
â”‚                                                                â”‚
â”‚ # Stage 1: Load Data (10TB Parquet)                            â”‚
â”‚ df = spark.read.parquet("/data/user_behavior_10tb.parquet")    â”‚
â”‚   â†’ 10,000 partitions (1GB each)                               â”‚
â”‚   â†’ 100 executors Ã— 100 partitions each                        â”‚
â”‚   â†’ Each executor loads 100GB                                  â”‚
â”‚                                                                â”‚
â”‚ # Stage 2: Feature Engineering                                 â”‚
â”‚ features = df.groupBy("user_id").agg(...)                      â”‚
â”‚   â†’ Shuffle (group by user_id)                                 â”‚
â”‚   â†’ 100 billion user events â†’ 500 million users                â”‚
â”‚   â†’ Each executor processes 5 million users                    â”‚
â”‚                                                                â”‚
â”‚ # Stage 3: Train Model (ALS)                                   â”‚
â”‚ model = ALS(rank=50, maxIter=10).fit(features)                 â”‚
â”‚   â†’ Iterative algorithm (10 iterations)                        â”‚
â”‚   â†’ Each iteration: 100 executors Ã— 16 cores = 1600 parallel   â”‚
â”‚   â†’ Total training time: 4 hours                               â”‚
â”‚                                                                â”‚
â”‚ # Stage 4: Save Model                                          â”‚
â”‚ model.save("/models/output")                                   â”‚
â”‚   â†’ Model size: 50GB                                           â”‚
â”‚   â†’ Saved to distributed storage (HDFS/S3)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Cost Analysis (AWS):
- 50 workers: r5.8xlarge ($2.016/hour Ã— 50) = $100.80/hour
- Training time: 4 hours
- Total cost: $403.20 per training run
```

### Example 3: Real-Time Stream Processing

**Scenario:** Process 1 million events/second from Kafka

```
Infrastructure:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafka Cluster (Event Source)                                   â”‚
â”‚ - Topic: user_events                                           â”‚
â”‚ - Partitions: 100                                              â”‚
â”‚ - Throughput: 1M events/second                                 â”‚
â”‚ - Event size: 1KB average                                      â”‚
â”‚ - Total: 1GB/second                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WhereQ Libra (Driver)                                          â”‚
â”‚                                                                â”‚
â”‚ Long-running Spark Streaming application:                      â”‚
â”‚                                                                â”‚
â”‚ val stream = spark                                             â”‚
â”‚   .readStream                                                  â”‚
â”‚   .format("kafka")                                             â”‚
â”‚   .option("kafka.bootstrap.servers", "kafka:9092")             â”‚
â”‚   .option("subscribe", "user_events")                          â”‚
â”‚   .load()                                                      â”‚
â”‚                                                                â”‚
â”‚ stream                                                         â”‚
â”‚   .selectExpr("CAST(value AS STRING)")                         â”‚
â”‚   .groupBy(window($"timestamp", "1 minute"), $"event_type")    â”‚
â”‚   .count()                                                     â”‚
â”‚   .writeStream                                                 â”‚
â”‚   .outputMode("update")                                        â”‚
â”‚   .format("console")                                           â”‚
â”‚   .start()                                                     â”‚
â”‚   .awaitTermination()                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 20 Executors (Continuous Processing)                           â”‚
â”‚                                                                â”‚
â”‚ Each executor:                                                 â”‚
â”‚ - Reads from 5 Kafka partitions                                â”‚
â”‚ - Processes ~50,000 events/second                              â”‚
â”‚ - Memory: 16GB (for windowed aggregations)                     â”‚
â”‚ - Cores: 8 (parallel task processing)                          â”‚
â”‚                                                                â”‚
â”‚ Micro-batch every 1 second:                                    â”‚
â”‚ - Executor 1: Partitions 0-4   â†’ 250K events                   â”‚
â”‚ - Executor 2: Partitions 5-9   â†’ 250K events                   â”‚
â”‚ - Executor 3: Partitions 10-14 â†’ 250K events                   â”‚
â”‚ - ...                                                          â”‚
â”‚ - Executor 20: Partitions 95-99 â†’ 250K events                  â”‚
â”‚                                                                â”‚
â”‚ Total: 1M events/second processed                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Driver's Role:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Every micro-batch (1 second):                                  â”‚
â”‚                                                                â”‚
â”‚ 1. Driver receives Kafka offsets                               â”‚
â”‚    - Partition 0: offset 1000-1050                             â”‚
â”‚    - Partition 1: offset 2000-2050                             â”‚
â”‚    - ... (100 partitions)                                      â”‚
â”‚                                                                â”‚
â”‚ 2. Driver creates 100 tasks (1 per Kafka partition)            â”‚
â”‚    - Task 1: Read partition 0, offsets 1000-1050               â”‚
â”‚    - Task 2: Read partition 1, offsets 2000-2050               â”‚
â”‚    - ... assign to 20 executors                                â”‚
â”‚                                                                â”‚
â”‚ 3. Executors process in parallel:                              â”‚
â”‚    - Parse JSON events                                         â”‚
â”‚    - Apply windowed aggregation (1-minute tumbling windows)    â”‚
â”‚    - Update state store                                        â”‚
â”‚                                                                â”‚
â”‚ 4. Driver collects results and outputs:                        â”‚
â”‚    - Window [10:00:00 - 10:01:00]:                             â”‚
â”‚      - click: 30,000                                           â”‚
â”‚      - view: 50,000                                            â”‚
â”‚      - purchase: 2,000                                         â”‚
â”‚                                                                â”‚
â”‚ 5. Driver commits Kafka offsets                                â”‚
â”‚    - Ensures exactly-once processing                           â”‚
â”‚                                                                â”‚
â”‚ Repeat every second...                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Common Misconceptions

### âŒ Misconception 1: "Master executes tasks"

**Wrong:** The Master (cluster manager) executes Spark tasks.

**Correct:** The Master only **allocates resources**. Executors execute tasks.

```
âŒ WRONG:
Master â†’ Runs your map/reduce logic

âœ“ CORRECT:
Master â†’ Allocates executors
Executors â†’ Run your map/reduce logic
```

---

### âŒ Misconception 2: "Driver is the Master"

**Wrong:** Driver and Master are the same thing.

**Correct:** Driver and Master are **separate components** with different roles.

```
Master (Cluster Manager):
- Manages cluster resources
- Allocates executors to applications
- Monitors worker health
- One per cluster

Driver (Application Coordinator):
- Runs your application logic
- Schedules tasks
- Collects results
- One per application
```

---

### âŒ Misconception 3: "Workers execute tasks"

**Wrong:** Worker nodes directly execute Spark tasks.

**Correct:** Workers **launch executors**, and executors execute tasks.

```
Worker Node (Physical Machine):
â”œâ”€ Executor 1 (JVM process)
â”‚  â””â”€ Task 1, Task 2, Task 3  â† These execute your code
â”œâ”€ Executor 2 (JVM process)
â”‚  â””â”€ Task 4, Task 5, Task 6  â† These execute your code
â””â”€ OS, Network, Storage
```

---

### âŒ Misconception 4: "More executors = better performance"

**Wrong:** Always max out number of executors.

**Correct:** Balance executors with cores and memory.

```
Bad Configuration:
--num-executors 1000
--executor-cores 1
--executor-memory 1g

Result:
- 1000 tiny executors
- High overhead (1000 JVMs)
- Poor data locality
- Excessive network shuffling

Good Configuration:
--num-executors 50
--executor-cores 8
--executor-memory 16g

Result:
- 50 well-sized executors (400 cores total)
- Lower overhead
- Better data locality
- Efficient shuffling
```

**Rule of Thumb:**
- **Executor cores:** 4-8 cores per executor (sweet spot: 5)
- **Executor memory:** 8-64GB per executor
- **Total executors:** Depends on data size and cluster capacity

---

### âŒ Misconception 5: "Libra is a proxy like Livy"

**Wrong:** Libra forwards requests to a separate Spark driver.

**Correct:** Libra **IS** the Spark driver (embedded model).

```
Apache Livy (Proxy):
Client â†’ Livy Server â†’ Spark Driver â†’ Executors
         (Proxy)       (Separate JVM)

WhereQ Libra (Embedded):
Client â†’ Libra (Driver + API) â†’ Executors
         (Single JVM)

Benefits of Embedded Model:
âœ“ Lower latency (no proxy overhead)
âœ“ Simplified architecture
âœ“ Direct SparkSession access
âœ“ Better resource utilization
```

---

## Summary Table

| Component | Type | Runs Where | Key Responsibility | Lifespan |
|-----------|------|------------|-------------------|----------|
| **Driver** | JVM Process | Client machine OR cluster node | Analyzes code, schedules tasks, collects results | Per application |
| **Master** | Service | Cluster master node | Allocates resources, monitors cluster | Cluster lifetime |
| **Worker** | Service | Cluster worker nodes | Launches executors, reports resources | Cluster lifetime |
| **Executor** | JVM Process | Worker nodes | Executes tasks, stores data | Per application |

### Key Relationships:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hierarchical View                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Cluster (Infrastructure)                                   â”‚
â”‚  â”œâ”€ Master (Resource Manager)                               â”‚
â”‚  â”‚  â””â”€ Manages workers                                      â”‚
â”‚  â”‚                                                          â”‚
â”‚  â””â”€ Workers (Physical Machines)                             â”‚
â”‚     â””â”€ Launch executors                                     â”‚
â”‚                                                             â”‚
â”‚  Application (Your Code)                                    â”‚
â”‚  â”œâ”€ Driver (Coordinator)                                    â”‚
â”‚  â”‚  â””â”€ Creates tasks, collects results                      â”‚
â”‚  â”‚                                                          â”‚
â”‚  â””â”€ Executors (Compute)                                     â”‚
â”‚     â””â”€ Run tasks, store data                                â”‚
â”‚                                                             â”‚
â”‚  Relationship:                                              â”‚
â”‚  Driver requests resources from Master                      â”‚
â”‚  Master allocates executors on Workers                      â”‚
â”‚  Driver sends tasks to Executors                            â”‚
â”‚  Executors execute tasks and return results to Driver       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## WhereQ Libra Quick Reference

### When Libra is the Driver (SHARED Mode):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Libra Container                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ SparkSession (Driver)         â”‚ â”‚
â”‚ â”‚ â”œâ”€ Job 1 (sql)                â”‚ â”‚
â”‚ â”‚ â”œâ”€ Job 2 (python code)        â”‚ â”‚
â”‚ â”‚ â””â”€ Job 3 (jar-class, no cfg)  â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                   â”‚
â”‚ All jobs share:                   â”‚
â”‚ - Same SparkSession               â”‚
â”‚ - Same executors                  â”‚
â”‚ - Global resource config          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### When Libra Launches Separate Drivers (ISOLATED Mode):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Libra Container (REST API)        â”‚
â”‚                                   â”‚
â”‚ Launches spark-submit:            â”‚
â”‚ â”œâ”€ Driver 1 (jar with cfg)        â”‚
â”‚ â”‚  â””â”€ Dedicated executors         â”‚
â”‚ â”‚                                 â”‚
â”‚ â”œâ”€ Driver 2 (python-file)         â”‚
â”‚ â”‚  â””â”€ Dedicated executors         â”‚
â”‚ â”‚                                 â”‚
â”‚ â””â”€ Driver 3 (jar-class + cfg)     â”‚
â”‚    â””â”€ Dedicated executors         â”‚
â”‚                                   â”‚
â”‚ Each job isolated with custom     â”‚
â”‚ resource configurations           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**End of Document**

For more information:
- [Apache Spark Architecture Documentation](https://spark.apache.org/docs/latest/cluster-overview.html)
- [WhereQ Libra README](../README.md)
- [Where Is The Driver?](WHERE_IS_THE_DRIVER.md)
- [Driver Performance Impact](DRIVER_PERFORMANCE_IMPACT.md)
- [Resource Allocation Guide](RESOURCE_ALLOCATION.md)
